"""
This type stub file was generated by pyright.
"""

from typing import Callable, ParamSpec, TypeVar

import contextlib as cl

_P = ParamSpec("_P")
_R = TypeVar("_R")

"""Core disk and file backed cache API.
"""

def full_name(func):
    """Return full name of `func` by adding the module and function name."""
    ...

class Constant(tuple):
    """Pretty display of immutable constant."""
    def __new__(cls, name):  # -> Self:
        ...
    def __repr__(self): ...

DBNAME = ...
ENOVAL = ...
UNKNOWN = ...
MODE_NONE = ...
MODE_RAW = ...
MODE_BINARY = ...
MODE_TEXT = ...
MODE_PICKLE = ...
DEFAULT_SETTINGS = ...
METADATA = ...
EVICTION_POLICY = ...

class Disk:
    """Cache key and value serialization for SQLite database and files."""
    def __init__(self, directory, min_file_size=..., pickle_protocol=...) -> None:
        """Initialize disk instance.

        :param str directory: directory path
        :param int min_file_size: minimum size for file use
        :param int pickle_protocol: pickle protocol for serialization

        """
        ...

    def hash(self, key):  # -> int:
        """Compute portable hash for `key`.

        :param key: key to hash
        :return: hash value

        """
        ...

    def put(
        self, key
    ):  # -> tuple[memoryview[int], Literal[True]] | tuple[Any, Literal[True]] | tuple[memoryview[int], Literal[False]]:
        """Convert `key` to fields key and raw for Cache table.

        :param key: key to convert
        :return: (database key, raw boolean) pair

        """
        ...

    def get(self, key, raw):  # -> bytes | Any:
        """Convert fields `key` and `raw` from Cache table to key.

        :param key: database key to convert
        :param bool raw: flag indicating raw database storage
        :return: corresponding Python key

        """
        ...

    def store(
        self, value, read, key=...
    ):  # -> tuple[Literal[0], Literal[1], None, Any] | tuple[Literal[0], Literal[1], None, memoryview[int]] | tuple[int, Literal[2], str, None] | tuple[int, Literal[3], str, None] | tuple[int | None, Literal[2], str, None] | tuple[Literal[0], Literal[4], None, memoryview[int]] | tuple[int, Literal[4], str, None]:
        """Convert `value` to fields size, mode, filename, and value for Cache
        table.

        :param value: value to convert
        :param bool read: True when value is file-like object
        :param key: key for item (default UNKNOWN)
        :return: (size, mode, filename, value) tuple for Cache table

        """
        ...

    def fetch(
        self, mode, filename, value, read
    ):  # -> bytes | BufferedReader[_BufferedReaderStream] | str | Any | None:
        """Convert fields `mode`, `filename`, and `value` from Cache table to
        value.

        :param int mode: value mode raw, binary, text, or pickle
        :param str filename: filename of corresponding value
        :param value: database value
        :param bool read: when True, return an open file handle
        :return: corresponding Python value
        :raises: IOError if the value cannot be read

        """
        ...

    def filename(self, key=..., value=...):  # -> tuple[str, str]:
        """Return filename and full-path tuple for file storage.

        Filename will be a randomly generated 28 character hexadecimal string
        with ".val" suffixed. Two levels of sub-directories will be used to
        reduce the size of directories. On older filesystems, lookups in
        directories with many files may be slow.

        The default implementation ignores the `key` and `value` parameters.

        In some scenarios, for example :meth:`Cache.push
        <diskcache.Cache.push>`, the `key` or `value` may not be known when the
        item is stored in the cache.

        :param key: key for item (default UNKNOWN)
        :param value: value for item (default UNKNOWN)

        """
        ...

    def remove(self, file_path):  # -> None:
        """Remove a file given by `file_path`.

        This method is cross-thread and cross-process safe. If an OSError
        occurs, it is suppressed.

        :param str file_path: relative path to file

        """
        ...

class JSONDisk(Disk):
    """Cache key and value using JSON serialization with zlib compression."""
    def __init__(self, directory, compress_level=..., **kwargs) -> None:
        """Initialize JSON disk instance.

        Keys and values are compressed using the zlib library. The
        `compress_level` is an integer from 0 to 9 controlling the level of
        compression; 1 is fastest and produces the least compression, 9 is
        slowest and produces the most compression, and 0 is no compression.

        :param str directory: directory path
        :param int compress_level: zlib compression level (default 1)
        :param kwargs: super class arguments

        """
        ...

    def put(
        self, key
    ):  # -> tuple[memoryview[int], Literal[True]] | tuple[Any, Literal[True]] | tuple[memoryview[int], Literal[False]]:
        ...
    def get(self, key, raw):  # -> Any:
        ...
    def store(
        self, value, read, key=...
    ):  # -> tuple[Literal[0], Literal[1], None, Any] | tuple[Literal[0], Literal[1], None, memoryview[int]] | tuple[int, Literal[2], str, None] | tuple[int, Literal[3], str, None] | tuple[int | None, Literal[2], str, None] | tuple[Literal[0], Literal[4], None, memoryview[int]] | tuple[int, Literal[4], str, None]:
        ...
    def fetch(
        self, mode, filename, value, read
    ):  # -> Any | bytes | BufferedReader[_BufferedReaderStream] | str | None:
        ...

class Timeout(Exception):
    """Database timeout expired."""

    ...

class UnknownFileWarning(UserWarning):
    """Warning used by Cache.check for unknown files."""

    ...

class EmptyDirWarning(UserWarning):
    """Warning used by Cache.check for empty directories."""

    ...

def args_to_key(base, args, kwargs, typed, ignore):
    """Create cache key out of function arguments.

    :param tuple base: base of key
    :param tuple args: function arguments
    :param dict kwargs: function keyword arguments
    :param bool typed: include types in cache key
    :param set ignore: positional or keyword args to ignore
    :return: cache key tuple

    """
    ...

class Cache:
    """Disk and file backed cache."""
    def __init__(self, directory=..., timeout=..., disk=..., **settings) -> None:
        """Initialize cache instance.

        :param str directory: cache directory
        :param float timeout: SQLite connection timeout
        :param disk: Disk type or subclass for serialization
        :param settings: any of DEFAULT_SETTINGS

        """
        ...

    @property
    def directory(self):  # -> str:
        """Cache directory."""
        ...

    @property
    def timeout(self):  # -> int:
        """SQLite connection timeout value in seconds."""
        ...

    @property
    def disk(self):  # -> Disk:
        """Disk used for serialization."""
        ...

    @cl.contextmanager
    def transact(self, retry=...):  # -> Generator[None, Any, None]:
        """Context manager to perform a transaction by locking the cache.

        While the cache is locked, no other write operation is permitted.
        Transactions should therefore be as short as possible. Read and write
        operations performed in a transaction are atomic. Read operations may
        occur concurrent to a transaction.

        Transactions may be nested and may not be shared between threads.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        >>> cache = Cache()
        >>> with cache.transact():  # Atomically increment two keys.
        ...     _ = cache.incr('total', 123.4)
        ...     _ = cache.incr('count', 1)
        >>> with cache.transact():  # Atomically calculate average.
        ...     average = cache['total'] / cache['count']
        >>> average
        123.4

        :param bool retry: retry if database timeout occurs (default False)
        :return: context manager for use in `with` statement
        :raises Timeout: if database timeout occurs

        """
        ...

    def set(
        self, key, value, expire=..., read=..., tag=..., retry=...
    ):  # -> Literal[True]:
        """Set `key` and `value` item in cache.

        When `read` is `True`, `value` should be a file-like object opened
        for reading in binary mode.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param key: key for item
        :param value: value for item
        :param float expire: seconds until item expires
            (default None, no expiry)
        :param bool read: read value as bytes from file (default False)
        :param str tag: text to associate with key (default None)
        :param bool retry: retry if database timeout occurs (default False)
        :return: True if item was set
        :raises Timeout: if database timeout occurs

        """
        ...

    def __setitem__(self, key, value):  # -> None:
        """Set corresponding `value` for `key` in cache.

        :param key: key for item
        :param value: value for item
        :return: corresponding value
        :raises KeyError: if key is not found

        """
        ...

    def touch(self, key, expire=..., retry=...):  # -> bool:
        """Touch `key` in cache and update `expire` time.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param key: key for item
        :param float expire: seconds until item expires
            (default None, no expiry)
        :param bool retry: retry if database timeout occurs (default False)
        :return: True if key was touched
        :raises Timeout: if database timeout occurs

        """
        ...

    def add(self, key, value, expire=..., read=..., tag=..., retry=...):  # -> bool:
        """Add `key` and `value` item to cache.

        Similar to `set`, but only add to cache if key not present.

        Operation is atomic. Only one concurrent add operation for a given key
        will succeed.

        When `read` is `True`, `value` should be a file-like object opened
        for reading in binary mode.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param key: key for item
        :param value: value for item
        :param float expire: seconds until the key expires
            (default None, no expiry)
        :param bool read: read value as bytes from file (default False)
        :param str tag: text to associate with key (default None)
        :param bool retry: retry if database timeout occurs (default False)
        :return: True if item was added
        :raises Timeout: if database timeout occurs

        """
        ...

    def incr(self, key, delta=..., default=..., retry=...):  # -> int | Any:
        """Increment value by delta for item with key.

        If key is missing and default is None then raise KeyError. Else if key
        is missing and default is not None then use default for value.

        Operation is atomic. All concurrent increment operations will be
        counted individually.

        Assumes value may be stored in a SQLite column. Most builds that target
        machines with 64-bit pointer widths will support 64-bit signed
        integers.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param key: key for item
        :param int delta: amount to increment (default 1)
        :param int default: value if key is missing (default 0)
        :param bool retry: retry if database timeout occurs (default False)
        :return: new value for item
        :raises KeyError: if key is not found and default is None
        :raises Timeout: if database timeout occurs

        """
        ...

    def decr(self, key, delta=..., default=..., retry=...):  # -> int | Any:
        """Decrement value by delta for item with key.

        If key is missing and default is None then raise KeyError. Else if key
        is missing and default is not None then use default for value.

        Operation is atomic. All concurrent decrement operations will be
        counted individually.

        Unlike Memcached, negative values are supported. Value may be
        decremented below zero.

        Assumes value may be stored in a SQLite column. Most builds that target
        machines with 64-bit pointer widths will support 64-bit signed
        integers.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param key: key for item
        :param int delta: amount to decrement (default 1)
        :param int default: value if key is missing (default 0)
        :param bool retry: retry if database timeout occurs (default False)
        :return: new value for item
        :raises KeyError: if key is not found and default is None
        :raises Timeout: if database timeout occurs

        """
        ...

    def get(
        self, key, default=..., read=..., expire_time=..., tag=..., retry=...
    ):  # -> tuple[Any | None, None, None] | tuple[Any | None, None] | tuple[bytes | Any | BufferedReader[_BufferedReaderStream] | str | None, Any, Any] | tuple[bytes | Any | BufferedReader[_BufferedReaderStream] | str | None, Any] | bytes | BufferedReader[_BufferedReaderStream] | str | Any | None:
        """Retrieve value from cache. If `key` is missing, return `default`.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param key: key for item
        :param default: value to return if key is missing (default None)
        :param bool read: if True, return file handle to value
            (default False)
        :param bool expire_time: if True, return expire_time in tuple
            (default False)
        :param bool tag: if True, return tag in tuple (default False)
        :param bool retry: retry if database timeout occurs (default False)
        :return: value for item or default if key not found
        :raises Timeout: if database timeout occurs

        """
        ...

    def __getitem__(
        self, key
    ):  # -> tuple[Any | None, None, None] | tuple[Any | None, None] | tuple[bytes | Any | BufferedReader[_BufferedReaderStream] | str | None, Any, Any] | tuple[bytes | Any | BufferedReader[_BufferedReaderStream] | str | None, Any] | bytes | BufferedReader[_BufferedReaderStream] | str | Any | None:
        """Return corresponding value for `key` from cache.

        :param key: key matching item
        :return: corresponding value
        :raises KeyError: if key is not found

        """
        ...

    def read(
        self, key, retry=...
    ):  # -> tuple[Any | None, None, None] | tuple[Any | None, None] | tuple[bytes | Any | BufferedReader[_BufferedReaderStream] | str | None, Any, Any] | tuple[bytes | Any | BufferedReader[_BufferedReaderStream] | str | None, Any] | bytes | BufferedReader[_BufferedReaderStream] | str | Any | None:
        """Return file handle value corresponding to `key` from cache.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param key: key matching item
        :param bool retry: retry if database timeout occurs (default False)
        :return: file open for reading in binary mode
        :raises KeyError: if key is not found
        :raises Timeout: if database timeout occurs

        """
        ...

    def __contains__(self, key):  # -> bool:
        """Return `True` if `key` matching item is found in cache.

        :param key: key matching item
        :return: True if key matching item

        """
        ...

    def pop(
        self, key, default=..., expire_time=..., tag=..., retry=...
    ):  # -> tuple[Any | None, None, None] | tuple[Any | None, None] | tuple[bytes | Any | BufferedReader[_BufferedReaderStream] | str | None, Any, Any] | tuple[bytes | Any | BufferedReader[_BufferedReaderStream] | str | None, Any] | bytes | BufferedReader[_BufferedReaderStream] | str | Any | None:
        """Remove corresponding item for `key` from cache and return value.

        If `key` is missing, return `default`.

        Operation is atomic. Concurrent operations will be serialized.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param key: key for item
        :param default: value to return if key is missing (default None)
        :param bool expire_time: if True, return expire_time in tuple
            (default False)
        :param bool tag: if True, return tag in tuple (default False)
        :param bool retry: retry if database timeout occurs (default False)
        :return: value for item or default if key not found
        :raises Timeout: if database timeout occurs

        """
        ...

    def __delitem__(self, key, retry=...):  # -> Literal[True]:
        """Delete corresponding item for `key` from cache.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default `True`).

        :param key: key matching item
        :param bool retry: retry if database timeout occurs (default True)
        :raises KeyError: if key is not found
        :raises Timeout: if database timeout occurs

        """
        ...

    def delete(self, key, retry=...):  # -> bool:
        """Delete corresponding item for `key` from cache.

        Missing keys are ignored.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param key: key matching item
        :param bool retry: retry if database timeout occurs (default False)
        :return: True if item was deleted
        :raises Timeout: if database timeout occurs

        """
        ...

    def push(
        self, value, prefix=..., side=..., expire=..., read=..., tag=..., retry=...
    ):  # -> str | int | Any:
        """Push `value` onto `side` of queue identified by `prefix` in cache.

        When prefix is None, integer keys are used. Otherwise, string keys are
        used in the format "prefix-integer". Integer starts at 500 trillion.

        Defaults to pushing value on back of queue. Set side to 'front' to push
        value on front of queue. Side must be one of 'back' or 'front'.

        Operation is atomic. Concurrent operations will be serialized.

        When `read` is `True`, `value` should be a file-like object opened
        for reading in binary mode.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        See also `Cache.pull`.

        >>> cache = Cache()
        >>> print(cache.push('first value'))
        500000000000000
        >>> cache.get(500000000000000)
        'first value'
        >>> print(cache.push('second value'))
        500000000000001
        >>> print(cache.push('third value', side='front'))
        499999999999999
        >>> cache.push(1234, prefix='userids')
        'userids-500000000000000'

        :param value: value for item
        :param str prefix: key prefix (default None, key is integer)
        :param str side: either 'back' or 'front' (default 'back')
        :param float expire: seconds until the key expires
            (default None, no expiry)
        :param bool read: read value as bytes from file (default False)
        :param str tag: text to associate with key (default None)
        :param bool retry: retry if database timeout occurs (default False)
        :return: key for item in cache
        :raises Timeout: if database timeout occurs

        """
        ...

    def pull(
        self, prefix=..., default=..., side=..., expire_time=..., tag=..., retry=...
    ):  # -> tuple[Any, None, None] | tuple[Any, None] | tuple[tuple[Any, bytes | Any | BufferedReader[_BufferedReaderStream] | str | None], Any, Any] | tuple[tuple[Any, bytes | Any | BufferedReader[_BufferedReaderStream] | str | None], Any] | tuple[Any, bytes | Any | BufferedReader[_BufferedReaderStream] | str | None]:
        """Pull key and value item pair from `side` of queue in cache.

        When prefix is None, integer keys are used. Otherwise, string keys are
        used in the format "prefix-integer". Integer starts at 500 trillion.

        If queue is empty, return default.

        Defaults to pulling key and value item pairs from front of queue. Set
        side to 'back' to pull from back of queue. Side must be one of 'front'
        or 'back'.

        Operation is atomic. Concurrent operations will be serialized.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        See also `Cache.push` and `Cache.get`.

        >>> cache = Cache()
        >>> cache.pull()
        (None, None)
        >>> for letter in 'abc':
        ...     print(cache.push(letter))
        500000000000000
        500000000000001
        500000000000002
        >>> key, value = cache.pull()
        >>> print(key)
        500000000000000
        >>> value
        'a'
        >>> _, value = cache.pull(side='back')
        >>> value
        'c'
        >>> cache.push(1234, 'userids')
        'userids-500000000000000'
        >>> _, value = cache.pull('userids')
        >>> value
        1234

        :param str prefix: key prefix (default None, key is integer)
        :param default: value to return if key is missing
            (default (None, None))
        :param str side: either 'front' or 'back' (default 'front')
        :param bool expire_time: if True, return expire_time in tuple
            (default False)
        :param bool tag: if True, return tag in tuple (default False)
        :param bool retry: retry if database timeout occurs (default False)
        :return: key and value item pair or default if queue is empty
        :raises Timeout: if database timeout occurs

        """
        ...

    def peek(
        self, prefix=..., default=..., side=..., expire_time=..., tag=..., retry=...
    ):  # -> tuple[Any, None, None] | tuple[Any, None] | tuple[tuple[Any, bytes | Any | BufferedReader[_BufferedReaderStream] | str | None], Any, Any] | tuple[tuple[Any, bytes | Any | BufferedReader[_BufferedReaderStream] | str | None], Any] | tuple[Any, bytes | Any | BufferedReader[_BufferedReaderStream] | str | None]:
        """Peek at key and value item pair from `side` of queue in cache.

        When prefix is None, integer keys are used. Otherwise, string keys are
        used in the format "prefix-integer". Integer starts at 500 trillion.

        If queue is empty, return default.

        Defaults to peeking at key and value item pairs from front of queue.
        Set side to 'back' to pull from back of queue. Side must be one of
        'front' or 'back'.

        Expired items are deleted from cache. Operation is atomic. Concurrent
        operations will be serialized.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        See also `Cache.pull` and `Cache.push`.

        >>> cache = Cache()
        >>> for letter in 'abc':
        ...     print(cache.push(letter))
        500000000000000
        500000000000001
        500000000000002
        >>> key, value = cache.peek()
        >>> print(key)
        500000000000000
        >>> value
        'a'
        >>> key, value = cache.peek(side='back')
        >>> print(key)
        500000000000002
        >>> value
        'c'

        :param str prefix: key prefix (default None, key is integer)
        :param default: value to return if key is missing
            (default (None, None))
        :param str side: either 'front' or 'back' (default 'front')
        :param bool expire_time: if True, return expire_time in tuple
            (default False)
        :param bool tag: if True, return tag in tuple (default False)
        :param bool retry: retry if database timeout occurs (default False)
        :return: key and value item pair or default if queue is empty
        :raises Timeout: if database timeout occurs

        """
        ...

    def peekitem(
        self, last=..., expire_time=..., tag=..., retry=...
    ):  # -> tuple[tuple[bytes | Any, bytes | Any | BufferedReader[_BufferedReaderStream] | str | None], Any, Any] | tuple[tuple[bytes | Any, bytes | Any | BufferedReader[_BufferedReaderStream] | str | None], Any] | tuple[bytes | Any, bytes | Any | BufferedReader[_BufferedReaderStream] | str | None]:
        """Peek at key and value item pair in cache based on iteration order.

        Expired items are deleted from cache. Operation is atomic. Concurrent
        operations will be serialized.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        >>> cache = Cache()
        >>> for num, letter in enumerate('abc'):
        ...     cache[letter] = num
        >>> cache.peekitem()
        ('c', 2)
        >>> cache.peekitem(last=False)
        ('a', 0)

        :param bool last: last item in iteration order (default True)
        :param bool expire_time: if True, return expire_time in tuple
            (default False)
        :param bool tag: if True, return tag in tuple (default False)
        :param bool retry: retry if database timeout occurs (default False)
        :return: key and value item pair
        :raises KeyError: if cache is empty
        :raises Timeout: if database timeout occurs

        """
        ...

    def memoize(
        self,
        name: str | None = None,
        typed: bool = False,
        expire: float | None = None,
        tag: str | None = None,
        ignore: tuple[str, ...] | None = (),
    ) -> Callable[[Callable[_P, _R]], Callable[_P, _R]]: ...
    def check(self, fix=..., retry=...):  # -> list[WarningMessage]:
        """Check database and file system consistency.

        Intended for use in testing and post-mortem error analysis.

        While checking the Cache table for consistency, a writer lock is held
        on the database. The lock blocks other cache clients from writing to
        the database. For caches with many file references, the lock may be
        held for a long time. For example, local benchmarking shows that a
        cache with 1,000 file references takes ~60ms to check.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param bool fix: correct inconsistencies
        :param bool retry: retry if database timeout occurs (default False)
        :return: list of warnings
        :raises Timeout: if database timeout occurs

        """
        ...

    def create_tag_index(self):  # -> None:
        """Create tag index on cache database.

        It is better to initialize cache with `tag_index=True` than use this.

        :raises Timeout: if database timeout occurs

        """
        ...

    def drop_tag_index(self):  # -> None:
        """Drop tag index on cache database.

        :raises Timeout: if database timeout occurs

        """
        ...

    def evict(self, tag, retry=...):  # -> int:
        """Remove items with matching `tag` from cache.

        Removing items is an iterative process. In each iteration, a subset of
        items is removed. Concurrent writes may occur between iterations.

        If a :exc:`Timeout` occurs, the first element of the exception's
        `args` attribute will be the number of items removed before the
        exception occurred.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param str tag: tag identifying items
        :param bool retry: retry if database timeout occurs (default False)
        :return: count of rows removed
        :raises Timeout: if database timeout occurs

        """
        ...

    def expire(self, now=..., retry=...):  # -> int:
        """Remove expired items from cache.

        Removing items is an iterative process. In each iteration, a subset of
        items is removed. Concurrent writes may occur between iterations.

        If a :exc:`Timeout` occurs, the first element of the exception's
        `args` attribute will be the number of items removed before the
        exception occurred.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param float now: current time (default None, ``time.time()`` used)
        :param bool retry: retry if database timeout occurs (default False)
        :return: count of items removed
        :raises Timeout: if database timeout occurs

        """
        ...

    def cull(self, retry=...):  # -> int:
        """Cull items from cache until volume is less than size limit.

        Removing items is an iterative process. In each iteration, a subset of
        items is removed. Concurrent writes may occur between iterations.

        If a :exc:`Timeout` occurs, the first element of the exception's
        `args` attribute will be the number of items removed before the
        exception occurred.

        Raises :exc:`Timeout` error when database timeout occurs and `retry` is
        `False` (default).

        :param bool retry: retry if database timeout occurs (default False)
        :return: count of items removed
        :raises Timeout: if database timeout occurs

        """
        ...

    def clear(self, retry: bool = False) -> int: ...
    def iterkeys(self, reverse=...):  # -> Generator[bytes | Any, Any, None]:
        """Iterate Cache keys in database sort order.

        >>> cache = Cache()
        >>> for key in [4, 1, 3, 0, 2]:
        ...     cache[key] = key
        >>> list(cache.iterkeys())
        [0, 1, 2, 3, 4]
        >>> list(cache.iterkeys(reverse=True))
        [4, 3, 2, 1, 0]

        :param bool reverse: reverse sort order (default False)
        :return: iterator of Cache keys

        """
        ...

    def __iter__(self):  # -> Generator[bytes | Any | None, Any, None]:
        """Iterate keys in cache including expired items."""
        ...

    def __reversed__(self):  # -> Generator[bytes | Any | None, Any, None]:
        """Reverse iterate keys in cache including expired items."""
        ...

    def stats(self, enable=..., reset=...):  # -> tuple[Any | Constant, Any | Constant]:
        """Return cache statistics hits and misses.

        :param bool enable: enable collecting statistics (default True)
        :param bool reset: reset hits and misses to 0 (default False)
        :return: (hits, misses)

        """
        ...

    def volume(self):  # -> Any:
        """Return estimated total size of cache on disk.

        :return: size in bytes

        """
        ...

    def close(self):  # -> None:
        """Close database connection."""
        ...

    def __enter__(self):  # -> Self:
        ...
    def __exit__(self, *exception):  # -> None:
        ...
    def __len__(self):  # -> Any | Constant:
        """Count of items in cache including expired items."""
        ...

    def __getstate__(self):  # -> tuple[str, int, type[Disk]]:
        ...
    def __setstate__(self, state):  # -> None:
        ...
    def reset(self, key, value=..., update=...):  # -> Any | Constant:
        """Reset `key` and `value` item from Settings table.

        Use `reset` to update the value of Cache settings correctly. Cache
        settings are stored in the Settings table of the SQLite database. If
        `update` is ``False`` then no attempt is made to update the database.

        If `value` is not given, it is reloaded from the Settings
        table. Otherwise, the Settings table is updated.

        Settings with the ``disk_`` prefix correspond to Disk
        attributes. Updating the value will change the unprefixed attribute on
        the associated Disk instance.

        Settings with the ``sqlite_`` prefix correspond to SQLite
        pragmas. Updating the value will execute the corresponding PRAGMA
        statement.

        SQLite PRAGMA statements may be executed before the Settings table
        exists in the database by setting `update` to ``False``.

        :param str key: Settings key for item
        :param value: value for item (optional)
        :param bool update: update database Settings table (default True)
        :return: updated value for item
        :raises Timeout: if database timeout occurs

        """
        ...
